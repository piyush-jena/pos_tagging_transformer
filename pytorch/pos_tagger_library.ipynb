{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRVj9RDbjhPP",
        "outputId": "a3169896-44f6-45c8-f01d-2a0722547fbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b8ab40bd130>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import ast\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1337)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "GQX7FeiujltE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('test_data.csv')\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "valid_data = pd.read_csv('valid_data.csv')\n",
        "word_vectors = pd.read_csv('wv.csv')"
      ],
      "metadata": {
        "id": "CQeD_DBbjoXs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = {}\n",
        "dictionary_size = word_vectors['vectors'].shape[0]\n",
        "\n",
        "for i in range(dictionary_size):\n",
        "    wv = np.fromstring(word_vectors['vectors'][i][1:-1], sep=' ')\n",
        "    dictionary[word_vectors['word'][i]] = torch.from_numpy(wv)"
      ],
      "metadata": {
        "id": "MaqOKkiYjqSy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 64\n",
        "num_heads = 4\n",
        "batch_size = 30\n",
        "max_sequence_length = 64\n",
        "ffn_hidden = 256\n",
        "num_layers = 4\n",
        "learning_rate = 1e-3\n",
        "max_iters = 10000\n",
        "eval_interval = 500\n",
        "eval_iters = 10\n",
        "\n",
        "block_size = 10\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "qq7U4Gyi0xCG"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "X_valid = []\n",
        "y_valid = []\n",
        "\n",
        "for i in range(len(train_data)):\n",
        "    tokens = ast.literal_eval(train_data['tokens'][i])\n",
        "    pos_tags = ast.literal_eval(train_data['pos_tags'][i])\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for j in range(len(tokens)):\n",
        "        if (tokens[j] not in dictionary):\n",
        "            X += [torch.zeros(64)]\n",
        "        else:\n",
        "            X += [dictionary[tokens[j]]]\n",
        "        y += [torch.tensor(pos_tags[j])]\n",
        "    if len(tokens) < block_size:\n",
        "        for j in range(block_size-len(tokens)):\n",
        "            X += [torch.zeros(64)]\n",
        "            y += [torch.tensor(45)]\n",
        "\n",
        "    X_train.append(X)\n",
        "    y_train.append(y)\n",
        "\n",
        "for i in range(len(valid_data)):\n",
        "    tokens = ast.literal_eval(valid_data['tokens'][i])\n",
        "    pos_tags = ast.literal_eval(valid_data['pos_tags'][i])\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for j in range(len(tokens)):\n",
        "        if (tokens[j] not in dictionary):\n",
        "            X += [torch.zeros(64)]\n",
        "        else:\n",
        "            X += [dictionary[tokens[j]]]\n",
        "        y += [torch.tensor(pos_tags[j])]\n",
        "    if len(tokens) < block_size:\n",
        "        for j in range(block_size-len(tokens)):\n",
        "            X += [torch.zeros(64)]\n",
        "            y += [torch.tensor(45)]\n",
        "\n",
        "    X_valid.append(X)\n",
        "    y_valid.append(y)\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "    tokens = ast.literal_eval(test_data['tokens'][i])\n",
        "    pos_tags = ast.literal_eval(test_data['pos_tags'][i])\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for j in range(len(tokens)):\n",
        "        if (tokens[j] not in dictionary):\n",
        "            X += [torch.zeros(64)]\n",
        "        else:\n",
        "            X += [dictionary[tokens[j]]]\n",
        "        y += [torch.tensor(pos_tags[j])]\n",
        "    if len(tokens) < block_size:\n",
        "        for j in range(block_size-len(tokens)):\n",
        "            X += [torch.zeros(64)]\n",
        "            y += [torch.tensor(45)]\n",
        "\n",
        "    X_test.append(X)\n",
        "    y_test.append(y)"
      ],
      "metadata": {
        "id": "bkX5CGKkjsit"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "    xtemp = []\n",
        "    ytemp = []\n",
        "\n",
        "    if split == 'train':\n",
        "        X, Y = X_train, y_train\n",
        "    elif split == 'valid':\n",
        "        X, Y = X_valid, y_valid\n",
        "    else:\n",
        "        X, Y = X_test, y_test\n",
        "\n",
        "    ix = torch.randint(len(X), (batch_size, ))\n",
        "    for i in ix:\n",
        "        if len(X[i]) > block_size:\n",
        "            j = torch.randint(len(X[i]) - block_size, (1, ))\n",
        "            xtemp.append(torch.stack(X[i][j:j+block_size]))\n",
        "            ytemp.append(torch.stack(Y[i][j:j+block_size]))\n",
        "        else:\n",
        "            xtemp.append(torch.stack(X[i]))\n",
        "            ytemp.append(torch.stack(Y[i]))\n",
        "\n",
        "    x, y = torch.stack(xtemp), torch.stack(ytemp)\n",
        "    x, y = x.type(torch.FloatTensor), y\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "qAPyq4-8m3xv"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss(model):\n",
        "    out = {}\n",
        "    accuracy = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'valid']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "\n",
        "            N, _ = logits.shape\n",
        "            Y = Y.view(N)\n",
        "            total += N\n",
        "            for i in range(N):\n",
        "                probs = F.softmax(logits[i], -1)\n",
        "                idx = torch.multinomial(probs, num_samples=1)\n",
        "                if (idx in [21, 22, 23, 24, 25, 28, 29] and Y[i] in [21, 22, 23, 24, 25, 28, 29]):\n",
        "                    correct += 1\n",
        "                elif (idx in [37, 38, 39, 40, 41, 42] and Y[i] in [37, 38, 39, 40, 41, 42]):\n",
        "                    correct += 1\n",
        "                elif (idx in [16, 17, 18, 30, 31, 32] and Y[i] in [16, 17, 18, 30, 31, 32]):\n",
        "                    correct += 1\n",
        "                elif (idx not in [21, 22, 23, 24, 25, 28, 29, 37, 38, 39, 40, 41, 42, 16, 17, 18, 30, 31, 32] and Y[i] not in [21, 22, 23, 24, 25, 28, 29, 37, 38, 39, 40, 41, 42, 16, 17, 18, 30, 31, 32]):\n",
        "                    correct += 1\n",
        "\n",
        "        out[split] = losses.mean()\n",
        "        accuracy[split] = (float(correct)/total)\n",
        "    model.train()\n",
        "    return out, accuracy"
      ],
      "metadata": {
        "id": "oYqrRZhRyUZX"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self, embd_size, num_heads):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(embd_size, embd_size // num_heads, bias=False)\n",
        "        self.key = nn.Linear(embd_size, embd_size // num_heads, bias=False)\n",
        "        self.value = nn.Linear(embd_size, embd_size // num_heads, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, _, C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        v = self.value(x)\n",
        "        wei = q @ k.transpose(-1, -2) / (C ** 0.5)\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(d_model, num_heads) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        x = self.proj(x)\n",
        "        return x\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps=eps\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
        "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
        "        mean = inputs.mean(dim=dims, keepdim=True)\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "        std = (var + self.eps).sqrt()\n",
        "        y = (inputs - mean) / std\n",
        "        out = self.gamma * y  + self.beta\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, hidden):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d_model, hidden),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden, d_model),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pe[:x.size(1)]\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.attention = MultiheadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.ffn = FeedForward(d_model=d_model, hidden=ffn_hidden)\n",
        "        self.norm1 = LayerNorm(parameters_shape=[d_model])\n",
        "        self.norm2 = LayerNorm(parameters_shape=[d_model])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attention(self.norm1(x))\n",
        "        x = x + self.ffn(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, num_layers, block_size, d_input, d_output):\n",
        "        super().__init__()\n",
        "        self.position_embedding_table = PositionalEncoding(d_model, max_len = block_size)\n",
        "        self.layers = nn.Sequential(*[EncoderLayer(d_model, ffn_hidden, num_heads) for _ in range(num_layers)])\n",
        "        self.norm = LayerNorm(parameters_shape=[d_model])\n",
        "        self.linear = nn.Linear(d_model, d_output)\n",
        "\n",
        "    def forward(self, x, target=None):\n",
        "        embds = x + self.position_embedding_table(x)\n",
        "        embds = self.layers(embds)\n",
        "        embds = self.norm(embds)\n",
        "        logits = self.linear(embds)\n",
        "\n",
        "        if target is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            target = target.view(B*T)\n",
        "            loss = F.cross_entropy(logits, target)\n",
        "\n",
        "        return logits, loss"
      ],
      "metadata": {
        "id": "NQJwCJa60_U9"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(d_model, ffn_hidden, num_heads, num_layers, block_size, 64, 47)\n",
        "encoder = encoder.to(device)\n",
        "optimizer = torch.optim.AdamW(encoder.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\n",
        "print(sum(p.numel() for p in encoder.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vfbk2kS1b7e",
        "outputId": "a07b4ecf-73cd-43ea-e1bf-3ef35cbfa75d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.202351 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses, accuracy = estimate_loss(encoder)\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f} accuracy: {accuracy['train']:.4f} valid loss {losses['valid']:.4f} accuracy: {accuracy['valid']:.4f}\")\n",
        "\n",
        "    Xb, yb = get_batch('train')\n",
        "    _, loss = encoder(Xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "861hTS2-1eZ3",
        "outputId": "e721ced9-2737-4629-b3c5-c98542012e3f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 0.2332 accuracy: 0.9322 valid loss 0.4465 accuracy: 0.9113\n",
            "step 500: train loss 0.2566 accuracy: 0.9403 valid loss 0.4412 accuracy: 0.9069\n",
            "step 1000: train loss 0.2249 accuracy: 0.9387 valid loss 0.3962 accuracy: 0.9087\n",
            "step 1500: train loss 0.2285 accuracy: 0.9300 valid loss 0.4831 accuracy: 0.9044\n",
            "step 2000: train loss 0.2111 accuracy: 0.9375 valid loss 0.4484 accuracy: 0.9056\n",
            "step 2500: train loss 0.2035 accuracy: 0.9409 valid loss 0.3806 accuracy: 0.9241\n",
            "step 3000: train loss 0.2016 accuracy: 0.9425 valid loss 0.4952 accuracy: 0.8972\n",
            "step 3500: train loss 0.2198 accuracy: 0.9325 valid loss 0.4471 accuracy: 0.9050\n",
            "step 4000: train loss 0.2266 accuracy: 0.9322 valid loss 0.4538 accuracy: 0.9069\n",
            "step 4500: train loss 0.2172 accuracy: 0.9394 valid loss 0.4184 accuracy: 0.9131\n",
            "step 5000: train loss 0.2192 accuracy: 0.9425 valid loss 0.4295 accuracy: 0.9125\n",
            "step 5500: train loss 0.2171 accuracy: 0.9425 valid loss 0.4264 accuracy: 0.9150\n",
            "step 6000: train loss 0.1739 accuracy: 0.9553 valid loss 0.4533 accuracy: 0.9062\n",
            "step 6500: train loss 0.2157 accuracy: 0.9419 valid loss 0.3745 accuracy: 0.9194\n",
            "step 7000: train loss 0.2014 accuracy: 0.9459 valid loss 0.3999 accuracy: 0.9150\n",
            "step 7500: train loss 0.2369 accuracy: 0.9378 valid loss 0.4705 accuracy: 0.8916\n",
            "step 8000: train loss 0.1778 accuracy: 0.9450 valid loss 0.4761 accuracy: 0.9125\n",
            "step 8500: train loss 0.1856 accuracy: 0.9519 valid loss 0.4741 accuracy: 0.9056\n",
            "step 9000: train loss 0.2100 accuracy: 0.9444 valid loss 0.4144 accuracy: 0.9228\n",
            "step 9500: train loss 0.2087 accuracy: 0.9437 valid loss 0.4110 accuracy: 0.9141\n",
            "step 9999: train loss 0.2069 accuracy: 0.9359 valid loss 0.5049 accuracy: 0.8962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v-id9T461gv-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}