{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glybKoo589Ys",
        "outputId": "033e444b-2372-4ea8-aa79-b4139c504d36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import ast\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/piyush-jena/pos_tagging_transformer/main/data/test_data.csv\n",
        "!wget https://raw.githubusercontent.com/piyush-jena/pos_tagging_transformer/main/data/train_data.csv\n",
        "!wget https://raw.githubusercontent.com/piyush-jena/pos_tagging_transformer/main/data/valid_data.csv"
      ],
      "metadata": {
        "id": "o_-KrrpW1ljZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "orxYohiZ9QXW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('test_data.csv')\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "valid_data = pd.read_csv('valid_data.csv')\n",
        "word_vectors = pd.read_csv('drive/MyDrive/wv.csv')"
      ],
      "metadata": {
        "id": "-G4XOGVJ9TCp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = {}\n",
        "dictionary_size = word_vectors['vectors'].shape[0]\n",
        "\n",
        "for i in range(dictionary_size):\n",
        "    wv = np.fromstring(word_vectors['vectors'][i][1:-1], sep=' ')\n",
        "    dictionary[word_vectors['word'][i]] = torch.from_numpy(wv)"
      ],
      "metadata": {
        "id": "cLf5kiKg9cQN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cmp(s, dt, t):\n",
        "  ex = torch.all(dt == t.grad).item()\n",
        "  app = torch.allclose(dt, t.grad)\n",
        "  maxdiff = (dt - t.grad).abs().max().item()\n",
        "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
      ],
      "metadata": {
        "id": "KxAPx4WvJ5D2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 64\n",
        "num_heads = 4\n",
        "max_sequence_length = 64\n",
        "ffn_hidden = 256\n",
        "num_layers = 4\n",
        "learning_rate = 1e-3\n",
        "max_iters = 10000\n",
        "eval_interval = 500\n",
        "eval_iters = 10\n",
        "\n",
        "block_size = 10\n",
        "batch_size = 1"
      ],
      "metadata": {
        "id": "F6Ph1cVD9gF-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "X_valid = []\n",
        "y_valid = []\n",
        "\n",
        "for i in range(len(train_data)):\n",
        "    tokens = ast.literal_eval(train_data['tokens'][i])\n",
        "    pos_tags = ast.literal_eval(train_data['pos_tags'][i])\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for j in range(len(tokens)):\n",
        "        if (tokens[j] not in dictionary):\n",
        "            X += [torch.zeros(64)]\n",
        "        else:\n",
        "            X += [dictionary[tokens[j]]]\n",
        "        y += [torch.tensor(pos_tags[j])]\n",
        "    if len(tokens) < block_size:\n",
        "        for j in range(block_size-len(tokens)):\n",
        "            X += [torch.zeros(64)]\n",
        "            y += [torch.tensor(45)]\n",
        "\n",
        "    X_train.append(X)\n",
        "    y_train.append(y)\n",
        "\n",
        "for i in range(len(valid_data)):\n",
        "    tokens = ast.literal_eval(valid_data['tokens'][i])\n",
        "    pos_tags = ast.literal_eval(valid_data['pos_tags'][i])\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for j in range(len(tokens)):\n",
        "        if (tokens[j] not in dictionary):\n",
        "            X += [torch.zeros(64)]\n",
        "        else:\n",
        "            X += [dictionary[tokens[j]]]\n",
        "        y += [torch.tensor(pos_tags[j])]\n",
        "    if len(tokens) < block_size:\n",
        "        for j in range(block_size-len(tokens)):\n",
        "            X += [torch.zeros(64)]\n",
        "            y += [torch.tensor(45)]\n",
        "\n",
        "    X_valid.append(X)\n",
        "    y_valid.append(y)\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "    tokens = ast.literal_eval(test_data['tokens'][i])\n",
        "    pos_tags = ast.literal_eval(test_data['pos_tags'][i])\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for j in range(len(tokens)):\n",
        "        if (tokens[j] not in dictionary):\n",
        "            X += [torch.zeros(64)]\n",
        "        else:\n",
        "            X += [dictionary[tokens[j]]]\n",
        "        y += [torch.tensor(pos_tags[j])]\n",
        "    if len(tokens) < block_size:\n",
        "        for j in range(block_size-len(tokens)):\n",
        "            X += [torch.zeros(64)]\n",
        "            y += [torch.tensor(45)]\n",
        "\n",
        "    X_test.append(X)\n",
        "    y_test.append(y)"
      ],
      "metadata": {
        "id": "WZbfIUpr9jE5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "    xtemp = []\n",
        "    ytemp = []\n",
        "\n",
        "    if split == 'train':\n",
        "        X, Y = X_train, y_train\n",
        "    elif split == 'valid':\n",
        "        X, Y = X_valid, y_valid\n",
        "    else:\n",
        "        X, Y = X_test, y_test\n",
        "\n",
        "    ix = torch.randint(len(X), (batch_size, ))\n",
        "    for i in ix:\n",
        "        if len(X[i]) > block_size:\n",
        "            j = torch.randint(len(X[i]) - block_size, (1, ))\n",
        "            xtemp.append(torch.stack(X[i][j:j+block_size]))\n",
        "            ytemp.append(torch.stack(Y[i][j:j+block_size]))\n",
        "        else:\n",
        "            xtemp.append(torch.stack(X[i]))\n",
        "            ytemp.append(torch.stack(Y[i]))\n",
        "\n",
        "    x, y = torch.stack(xtemp), torch.stack(ytemp)\n",
        "    x, y = x.type(torch.FloatTensor), y\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "1e2TfMTo9nOs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss(model):\n",
        "    out = {}\n",
        "    accuracy = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'valid']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "\n",
        "            N, _ = logits.shape\n",
        "            Y = Y.view(N)\n",
        "            total += N\n",
        "            for i in range(N):\n",
        "                probs = F.softmax(logits[i], -1)\n",
        "                idx = torch.multinomial(probs, num_samples=1)\n",
        "                if (idx in [21, 22, 23, 24, 25, 28, 29] and Y[i] in [21, 22, 23, 24, 25, 28, 29]):\n",
        "                    correct += 1\n",
        "                elif (idx in [37, 38, 39, 40, 41, 42] and Y[i] in [37, 38, 39, 40, 41, 42]):\n",
        "                    correct += 1\n",
        "                elif (idx in [16, 17, 18, 30, 31, 32] and Y[i] in [16, 17, 18, 30, 31, 32]):\n",
        "                    correct += 1\n",
        "                elif (idx not in [21, 22, 23, 24, 25, 28, 29, 37, 38, 39, 40, 41, 42, 16, 17, 18, 30, 31, 32] and Y[i] not in [21, 22, 23, 24, 25, 28, 29, 37, 38, 39, 40, 41, 42, 16, 17, 18, 30, 31, 32]):\n",
        "                    correct += 1\n",
        "\n",
        "        out[split] = losses.mean()\n",
        "        accuracy[split] = (float(correct)/total)\n",
        "    model.train()\n",
        "    return out, accuracy"
      ],
      "metadata": {
        "id": "1DqOD4qi9qKy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self, embd_size, num_heads):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(embd_size, embd_size // num_heads, bias=False)\n",
        "        self.key = nn.Linear(embd_size, embd_size // num_heads, bias=False)\n",
        "        self.value = nn.Linear(embd_size, embd_size // num_heads, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, _, C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        v = self.value(x)\n",
        "        wei = q @ k.transpose(-1, -2) / (C ** 0.5)\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(d_model, num_heads) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        x = self.proj(x)\n",
        "        return x\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps = eps\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
        "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
        "        mean = inputs.mean(dim=dims, keepdim=True)\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "        std = (var + self.eps).sqrt()\n",
        "        y = (inputs - mean) / std\n",
        "        out = self.gamma * y  + self.beta\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, hidden):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d_model, hidden),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden, d_model),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pe[:x.size(1)]\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.attention = MultiheadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.ffn = FeedForward(d_model=d_model, hidden=ffn_hidden)\n",
        "        self.norm1 = LayerNorm(parameters_shape=[d_model])\n",
        "        self.norm2 = LayerNorm(parameters_shape=[d_model])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attention(self.norm1(x))\n",
        "        x = x + self.ffn(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, num_layers, block_size, d_input, d_output):\n",
        "        super().__init__()\n",
        "        self.position_embedding_table = PositionalEncoding(d_model, max_len = block_size)\n",
        "        self.layers = nn.Sequential(*[EncoderLayer(d_model, ffn_hidden, num_heads) for _ in range(num_layers)])\n",
        "        self.norm = LayerNorm(parameters_shape=[d_model])\n",
        "        self.linear = nn.Linear(d_model, d_output)\n",
        "\n",
        "    def forward(self, x, target=None):\n",
        "        embds = x + self.position_embedding_table(x)\n",
        "        embds = self.layers(embds)\n",
        "        embds = self.norm(embds)\n",
        "        logits = self.linear(embds)\n",
        "\n",
        "        if target is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            target = target.view(B*T)\n",
        "            loss = F.cross_entropy(logits, target)\n",
        "        return logits, loss"
      ],
      "metadata": {
        "id": "o8lgf7D09wkY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = get_batch('train')"
      ],
      "metadata": {
        "id": "8J_HZw8sssR2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = batch_size\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "\n",
        "position_embedding_table = PositionalEncoding(d_model, max_len = block_size)\n",
        "\n",
        "W = torch.randn((d_model, 47), generator=g) * (5/3)/((d_model * 47)**0.5)\n",
        "b = torch.randn(47,            generator=g) * 0.1\n",
        "\n",
        "key11 = torch.randn((d_model, d_model // 2),          generator=g) * 0.1\n",
        "query11 = torch.randn((d_model, d_model // 2),          generator=g) * 0.1\n",
        "value11 = torch.randn((d_model, d_model // 2),          generator=g) * 0.1\n",
        "\n",
        "key12 = torch.randn((d_model, d_model // 2),          generator=g) * 0.1\n",
        "query12 = torch.randn((d_model, d_model // 2),          generator=g) * 0.1\n",
        "value12 = torch.randn((d_model, d_model // 2),          generator=g) * 0.1\n",
        "\n",
        "key21 = torch.randn((d_model, d_model // 2),          generator=g) * 0.1\n",
        "query21 = torch.randn((d_model, d_model // 2),          generator=g) * 0.1\n",
        "value21 = torch.randn((d_model, d_model // 2),          generator=g) * 0.1\n",
        "\n",
        "key22 = torch.randn((d_model, d_model // 2),          generator=g) * 0.1\n",
        "query22 = torch.randn((d_model, d_model // 2),          generator=g) * 0.1\n",
        "value22 = torch.randn((d_model, d_model // 2),          generator=g) * 0.1\n",
        "\n",
        "linear1 = torch.randn((d_model, d_model), generator=g) * (5/3)/((d_model * d_model)**0.5)\n",
        "bias1 = torch.randn(d_model,            generator=g) * 0.1\n",
        "\n",
        "linear2 = torch.randn((d_model, d_model), generator=g) * (5/3)/((d_model * d_model)**0.5)\n",
        "bias2 = torch.randn(d_model,            generator=g) * 0.1\n",
        "\n",
        "W11 = torch.randn((d_model, ffn_hidden), generator=g) * (5/3)/((d_model * ffn_hidden)**0.5)\n",
        "b11 = torch.randn(ffn_hidden,            generator=g) * 0.1\n",
        "\n",
        "W12 = torch.randn((ffn_hidden, d_model), generator=g) * (5/3)/((ffn_hidden * d_model)**0.5)\n",
        "b12 = torch.randn(d_model,            generator=g) * 0.1\n",
        "\n",
        "W21 = torch.randn((d_model, ffn_hidden), generator=g) * (5/3)/((d_model * ffn_hidden)**0.5)\n",
        "b21 = torch.randn(ffn_hidden,            generator=g) * 0.1\n",
        "\n",
        "W22 = torch.randn((ffn_hidden, d_model), generator=g) * (5/3)/((ffn_hidden * d_model)**0.5)\n",
        "b22 = torch.randn(d_model,            generator=g) * 0.1\n",
        "\n",
        "parameters = [W, b, W11, W12, W21, W22, b11, b12, b21, b22, linear1, bias1, linear2, bias2, key11, query11, value11, key21, query21, value21, key12, query12, value12, key22, query22, value22]\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnaouydNvwxe",
        "outputId": "5072bedc-1c0a-4885-f24c-2ea5abcea39b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_emb = position_embedding_table(x)\n",
        "embd = x + pos_emb\n",
        "\n",
        "_, _, C = embd.shape\n",
        "\n",
        "k11 = embd @ key11\n",
        "q11 = embd @ query11\n",
        "v11 = embd @ value11\n",
        "\n",
        "wei11 = q11 @ k11.transpose(-1, -2) / (C ** 0.5)\n",
        "swei11 = F.softmax(wei11, dim=-1)\n",
        "out11 = swei11 @ v11\n",
        "\n",
        "k12 = embd @ key12\n",
        "q12 = embd @ query12\n",
        "v12 = embd @ value12\n",
        "\n",
        "wei12 = q12 @ k12.transpose(-1, -2) / (C ** 0.5)\n",
        "swei12 = F.softmax(wei12, dim=-1)\n",
        "out12 = swei12 @ v12\n",
        "\n",
        "attention1 = torch.cat([out11, out12], dim=-1)\n",
        "attention_output1 = embd + attention1 @ linear1 + bias1\n",
        "ffn11 = attention_output1 @ W11 + b11\n",
        "affn11 = F.tanh(ffn11)\n",
        "ffn12 = affn11 @ W12 + b12\n",
        "encoder_output1 = attention_output1 + ffn12\n",
        "\n",
        "k21 = encoder_output1 @ key21\n",
        "q21 = encoder_output1 @ query21\n",
        "v21 = encoder_output1 @ value21\n",
        "\n",
        "wei21 = q21 @ k21.transpose(-1, -2) / (C ** 0.5)\n",
        "swei21 = F.softmax(wei21, dim=-1)\n",
        "out21 = swei21 @ v21\n",
        "\n",
        "k22 = encoder_output1 @ key22\n",
        "q22 = encoder_output1 @ query22\n",
        "v22 = encoder_output1 @ value22\n",
        "\n",
        "wei22 = q22 @ k22.transpose(-1, -2) / (C ** 0.5)\n",
        "swei22 = F.softmax(wei22, dim=-1)\n",
        "out22 = swei22 @ v22\n",
        "\n",
        "attention2 = torch.cat([out21, out22], dim=-1)\n",
        "attention_output2 = attention2 @ linear2 + bias2\n",
        "ffn21 = attention_output2 @ W21 + b21\n",
        "affn21 = F.tanh(ffn21)\n",
        "ffn22 = affn21 @ W22 + b22\n",
        "encoder_output2 = attention_output2 + ffn22\n",
        "logits = encoder_output2 @ W + b\n",
        "\n",
        "B, T, C1 = logits.shape\n",
        "logits1 = logits.view(B*T, C1)\n",
        "logit_maxes = logits1.max(1, keepdim=True).values\n",
        "norm_logits = logits1 - logit_maxes # subtract max for numerical stability\n",
        "counts = norm_logits.exp()\n",
        "counts_sum = counts.sum(1, keepdims=True)\n",
        "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
        "probs = counts * counts_sum_inv\n",
        "logprobs = probs.log()\n",
        "loss = -logprobs[range(block_size), y[0]].mean()\n",
        "\n",
        "for p in parameters:\n",
        "    p.grad = None\n",
        "for t in [logits1, logits, encoder_output2, encoder_output1, ffn22, ffn12, affn21, ffn21, # afaik there is no cleaner way\n",
        "          attention_output2, attention2, out22, swei22, wei22, v22,\n",
        "         q22, k22, out21, swei21, wei21, v21, q21, k21, affn11, ffn11,\n",
        "         attention_output1, attention1, out12, swei12, wei12, v12,\n",
        "         q12, k12, out11, swei11, wei11, v11, q11, k11]:\n",
        "    t.retain_grad()"
      ],
      "metadata": {
        "id": "__11DdNYt_QW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "RiwJBd0d4kBD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(block_size), y[0]] = -1.0/block_size\n",
        "dprobs = (1.0 / probs) * dlogprobs\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "dnorm_logits = counts * dcounts\n",
        "dlogits1 = dnorm_logits.clone()\n",
        "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
        "dlogits1 += F.one_hot(logits1.max(1).indices, num_classes=logits1.shape[1]) * dlogit_maxes\n",
        "dlogits = torch.unsqueeze(dlogits1, 0)\n",
        "\n",
        "dencoder_output2 = torch.unsqueeze(torch.squeeze(dlogits) @ W.T, 0)\n",
        "dW = torch.squeeze(encoder_output2.transpose(-2, -1) @ dlogits)\n",
        "db = torch.squeeze(dlogits.sum(1))\n",
        "dffn22 = dencoder_output2.clone()\n",
        "dattention_output2 = dencoder_output2.clone()\n",
        "\n",
        "daffn21 = dffn22 @ W22.T\n",
        "dW22 = torch.squeeze(affn21.transpose(-2, -1) @ dffn22)\n",
        "db22 = torch.squeeze(dffn22.sum(1))\n",
        "dffn21 = daffn21 * (1 - affn21**2)\n",
        "\n",
        "dattention_output2 += dffn21 @ W21.T\n",
        "dW21 = torch.squeeze(attention_output2.transpose(-2, -1) @ dffn21)\n",
        "db21 = torch.squeeze(dffn21.sum(1))\n",
        "dattention2 = dattention_output2 @ linear2.T\n",
        "dlinear2 = torch.squeeze(attention2.transpose(-2, -1) @ dattention_output2)\n",
        "dbias2 = torch.squeeze(dattention_output2.sum(1))\n",
        "dout21 = dattention2[:,:,:32]\n",
        "dout22 = dattention2[:,:,32:]\n",
        "\n",
        "dswei22 = dout22 @ v22.transpose(-2, -1)\n",
        "dv22 = torch.squeeze(swei22.transpose(-2, -1) @ dout22)\n",
        "\n",
        "dwei22 = torch.zeros([10, 10])\n",
        "for i in range(10):\n",
        "    dwei22[i, :] = (torch.unsqueeze(dswei22[0][i], 0) @ (-torch.outer(swei22[0][i], swei22[0][i]) + torch.diag(swei22[0][i])))\n",
        "dwei22 = torch.unsqueeze(dwei22, 0)\n",
        "\n",
        "dk22 = dwei22.transpose(-2, -1) @ q22 / (C ** 0.5)\n",
        "dq22 = dwei22 @ k22 / (C ** 0.5)\n",
        "\n",
        "dvalue22 = torch.squeeze(encoder_output1.transpose(-2, -1) @ dv22)\n",
        "dkey22 = torch.squeeze(encoder_output1.transpose(-2, -1) @ dk22)\n",
        "dquery22 = torch.squeeze(encoder_output1.transpose(-2, -1) @ dq22)\n",
        "\n",
        "dencoder_output1 = dv22 @ value22.transpose(-2, -1) + dq22 @ query22.transpose(-2, -1) + dk22 @ key22.transpose(-2, -1)\n",
        "\n",
        "dswei21 = dout21 @ v21.transpose(-2, -1)\n",
        "dv21 = torch.squeeze(swei21.transpose(-2, -1) @ dout21)\n",
        "\n",
        "dwei21 = torch.zeros([10, 10])\n",
        "for i in range(10):\n",
        "    dwei21[i, :] = (torch.unsqueeze(dswei21[0][i], 0) @ (-torch.outer(swei21[0][i], swei21[0][i]) + torch.diag(swei21[0][i])))\n",
        "dwei21 = torch.unsqueeze(dwei21, 0)\n",
        "\n",
        "dk21 = dwei21.transpose(-2, -1) @ q21 / (C ** 0.5)\n",
        "dq21 = dwei21 @ k21 / (C ** 0.5)\n",
        "\n",
        "dvalue21 = torch.squeeze(encoder_output1.transpose(-2, -1) @ dv21)\n",
        "dkey21 = torch.squeeze(encoder_output1.transpose(-2, -1) @ dk21)\n",
        "dquery21 = torch.squeeze(encoder_output1.transpose(-2, -1) @ dq21)\n",
        "\n",
        "dencoder_output1 += dv21 @ value21.transpose(-2, -1) + dq21 @ query21.transpose(-2, -1) + dk21 @ key21.transpose(-2, -1)\n",
        "\n",
        "dffn12 = dencoder_output1.clone()\n",
        "dattention_output1 = dencoder_output1.clone()\n",
        "\n",
        "daffn11 = dffn12 @ W12.T\n",
        "dW12 = torch.squeeze(affn11.transpose(-2, -1) @ dffn12)\n",
        "db12 = torch.squeeze(dffn12.sum(1))\n",
        "dffn11 = daffn11 * (1 - affn11**2)\n",
        "\n",
        "dattention_output1 += dffn11 @ W11.T\n",
        "dW11 = torch.squeeze(attention_output1.transpose(-2, -1) @ dffn11)\n",
        "db11 = torch.squeeze(dffn11.sum(1))\n",
        "dattention1 = dattention_output1 @ linear1.T\n",
        "dlinear1 = torch.squeeze(attention1.transpose(-2, -1) @ dattention_output1)\n",
        "dbias1 = torch.squeeze(dattention_output1.sum(1))\n",
        "dout11 = dattention1[:,:,:32]\n",
        "dout12 = dattention1[:,:,32:]\n",
        "\n",
        "dswei12 = dout12 @ v12.transpose(-2, -1)\n",
        "dv12 = torch.squeeze(swei12.transpose(-2, -1) @ dout12)\n",
        "\n",
        "dwei12 = torch.zeros([10, 10])\n",
        "for i in range(10):\n",
        "    dwei12[i, :] = (torch.unsqueeze(dswei12[0][i], 0) @ (-torch.outer(swei12[0][i], swei12[0][i]) + torch.diag(swei12[0][i])))\n",
        "dwei12 = torch.unsqueeze(dwei12, 0)\n",
        "\n",
        "dk12 = dwei12.transpose(-2, -1) @ q12 / (C ** 0.5)\n",
        "dq12 = dwei12 @ k12 / (C ** 0.5)\n",
        "\n",
        "dvalue12 = torch.squeeze(embd.transpose(-2, -1) @ dv12)\n",
        "dkey12 = torch.squeeze(embd.transpose(-2, -1) @ dk12)\n",
        "dquery12 = torch.squeeze(embd.transpose(-2, -1) @ dq12)\n",
        "\n",
        "dswei11 = dout11 @ v11.transpose(-2, -1)\n",
        "dv11 = torch.squeeze(swei11.transpose(-2, -1) @ dout11)\n",
        "\n",
        "dwei11 = torch.zeros([10, 10])\n",
        "for i in range(10):\n",
        "    dwei11[i, :] = (torch.unsqueeze(dswei11[0][i], 0) @ (-torch.outer(swei11[0][i], swei11[0][i]) + torch.diag(swei11[0][i])))\n",
        "dwei11 = torch.unsqueeze(dwei11, 0)\n",
        "\n",
        "dk11 = dwei11.transpose(-2, -1) @ q11 / (C ** 0.5)\n",
        "dq11 = dwei11 @ k11 / (C ** 0.5)\n",
        "\n",
        "dvalue11 = torch.squeeze(embd.transpose(-2, -1) @ dv11)\n",
        "dkey11 = torch.squeeze(embd.transpose(-2, -1) @ dk11)\n",
        "dquery11 = torch.squeeze(embd.transpose(-2, -1) @ dq11)"
      ],
      "metadata": {
        "id": "DVL5o7KJJGYa"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cmp('logits1', dlogits1, logits1)\n",
        "cmp('logits', dlogits, logits)\n",
        "cmp('encoder_output2', dencoder_output2, encoder_output2)\n",
        "cmp('W', dW, W)\n",
        "cmp('b', db, b)\n",
        "cmp('ffn22', dffn22, ffn22)\n",
        "cmp('affn21', daffn21, affn21)\n",
        "cmp('W22', dW22, W22)\n",
        "cmp('b22', db22, b22)\n",
        "cmp('ffn21', dffn21, ffn21)\n",
        "cmp('attention_output2', dattention_output2, attention_output2)\n",
        "cmp('W22', dW21, W21)\n",
        "cmp('b22', db21, b21)\n",
        "cmp('attention2', dattention2, attention2)\n",
        "cmp('linear2', dlinear2, linear2)\n",
        "cmp('bias2', dbias2, bias2)\n",
        "cmp('out21', dout21, out21)\n",
        "cmp('out22', dout22, out22)\n",
        "cmp('swei22', dswei22, swei22)\n",
        "cmp('wei22', dwei22, wei22)\n",
        "cmp('k22', dk22, k22)\n",
        "cmp('q22', dq22, q22)\n",
        "cmp('v22', dv22, v22)\n",
        "cmp('value22', dvalue22, value22)\n",
        "cmp('key22', dkey22, key22)\n",
        "cmp('query22', dquery22, query22)\n",
        "cmp('swei21', dswei21, swei21)\n",
        "cmp('wei21', dwei21, wei21)\n",
        "cmp('k21', dk21, k21)\n",
        "cmp('q21', dq21, q21)\n",
        "cmp('v21', dv21, v21)\n",
        "cmp('value21', dvalue21, value21)\n",
        "cmp('key21', dkey21, key21)\n",
        "cmp('query21', dquery21, query21)\n",
        "cmp('encoder_output1', dencoder_output1, encoder_output1)\n",
        "\n",
        "cmp('ffn12', dffn12, ffn12)\n",
        "cmp('affn11', daffn11, affn11)\n",
        "cmp('W12', dW12, W12)\n",
        "cmp('b12', db12, b12)\n",
        "cmp('ffn11', dffn11, ffn11)\n",
        "cmp('attention_output1', dattention_output1, attention_output1)\n",
        "cmp('W11', dW11, W11)\n",
        "cmp('b11', db11, b11)\n",
        "cmp('attention1', dattention1, attention1)\n",
        "cmp('linear1', dlinear1, linear1)\n",
        "cmp('bias1', dbias1, bias1)\n",
        "cmp('out11', dout11, out11)\n",
        "cmp('out12', dout12, out12)\n",
        "cmp('swei12', dswei12, swei12)\n",
        "cmp('wei12', dwei12, wei12)\n",
        "cmp('k12', dk12, k12)\n",
        "cmp('q12', dq12, q12)\n",
        "cmp('v12', dv12, v12)\n",
        "cmp('value12', dvalue12, value12)\n",
        "cmp('key12', dkey12, key12)\n",
        "cmp('query12', dquery12, query12)\n",
        "cmp('swei11', dswei11, swei11)\n",
        "cmp('wei11', dwei11, wei11)\n",
        "cmp('k11', dk11, k11)\n",
        "cmp('q11', dq11, q11)\n",
        "cmp('v11', dv11, v11)\n",
        "cmp('value11', dvalue11, value11)\n",
        "cmp('key11', dkey11, key11)\n",
        "cmp('query11', dquery11, query11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFmbIZdvK_Kx",
        "outputId": "c70f7eb8-d1dc-4de4-e378-a8178c2bf1c7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits1         | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
            "logits          | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
            "encoder_output2 | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n",
            "W               | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
            "b               | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
            "ffn22           | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n",
            "affn21          | exact: False | approximate: True  | maxdiff: 2.3283064365386963e-10\n",
            "W22             | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
            "b22             | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "ffn21           | exact: False | approximate: True  | maxdiff: 2.3283064365386963e-10\n",
            "attention_output2 | exact: False | approximate: True  | maxdiff: 1.1641532182693481e-09\n",
            "W22             | exact: False | approximate: True  | maxdiff: 1.1641532182693481e-10\n",
            "b22             | exact: False | approximate: True  | maxdiff: 5.820766091346741e-10\n",
            "attention2      | exact: False | approximate: True  | maxdiff: 5.820766091346741e-10\n",
            "linear2         | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "bias2           | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "out21           | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "out22           | exact: False | approximate: True  | maxdiff: 5.820766091346741e-10\n",
            "swei22          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
            "wei22           | exact: False | approximate: True  | maxdiff: 1.6007106751203537e-10\n",
            "k22             | exact: False | approximate: True  | maxdiff: 4.3655745685100555e-11\n",
            "q22             | exact: False | approximate: True  | maxdiff: 8.003553375601768e-11\n",
            "v22             | exact: False | approximate: True  | maxdiff: 1.1641532182693481e-10\n",
            "value22         | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n",
            "key22           | exact: False | approximate: True  | maxdiff: 3.7834979593753815e-10\n",
            "query22         | exact: False | approximate: True  | maxdiff: 3.4924596548080444e-10\n",
            "swei21          | exact: False | approximate: True  | maxdiff: 1.1641532182693481e-09\n",
            "wei21           | exact: False | approximate: True  | maxdiff: 7.275957614183426e-11\n",
            "k21             | exact: False | approximate: True  | maxdiff: 1.8189894035458565e-11\n",
            "q21             | exact: False | approximate: True  | maxdiff: 3.637978807091713e-11\n",
            "v21             | exact: False | approximate: True  | maxdiff: 1.1641532182693481e-10\n",
            "value21         | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
            "key21           | exact: False | approximate: True  | maxdiff: 1.1641532182693481e-10\n",
            "query21         | exact: False | approximate: True  | maxdiff: 5.911715561524034e-11\n",
            "encoder_output1 | exact: False | approximate: True  | maxdiff: 1.7462298274040222e-10\n",
            "ffn12           | exact: False | approximate: True  | maxdiff: 1.7462298274040222e-10\n",
            "affn11          | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-11\n",
            "W12             | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-10\n",
            "b12             | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n",
            "ffn11           | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-11\n",
            "attention_output1 | exact: False | approximate: True  | maxdiff: 1.7462298274040222e-10\n",
            "W11             | exact: False | approximate: True  | maxdiff: 3.4924596548080444e-10\n",
            "b11             | exact: False | approximate: True  | maxdiff: 1.1641532182693481e-10\n",
            "attention1      | exact: False | approximate: True  | maxdiff: 7.275957614183426e-11\n",
            "linear1         | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
            "bias1           | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n",
            "out11           | exact: False | approximate: True  | maxdiff: 5.820766091346741e-11\n",
            "out12           | exact: False | approximate: True  | maxdiff: 7.275957614183426e-11\n",
            "swei12          | exact: False | approximate: True  | maxdiff: 3.4924596548080444e-10\n",
            "wei12           | exact: False | approximate: True  | maxdiff: 2.000888343900442e-11\n",
            "k12             | exact: False | approximate: True  | maxdiff: 1.8189894035458565e-11\n",
            "q12             | exact: False | approximate: True  | maxdiff: 1.0913936421275139e-11\n",
            "v12             | exact: False | approximate: True  | maxdiff: 3.637978807091713e-11\n",
            "value12         | exact: False | approximate: True  | maxdiff: 5.820766091346741e-10\n",
            "key12           | exact: False | approximate: True  | maxdiff: 7.275957614183426e-11\n",
            "query12         | exact: False | approximate: True  | maxdiff: 5.820766091346741e-11\n",
            "swei11          | exact: False | approximate: True  | maxdiff: 1.6007106751203537e-10\n",
            "wei11           | exact: False | approximate: True  | maxdiff: 1.4551915228366852e-11\n",
            "k11             | exact: False | approximate: True  | maxdiff: 4.774847184307873e-12\n",
            "q11             | exact: False | approximate: True  | maxdiff: 5.229594535194337e-12\n",
            "v11             | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-11\n",
            "value11         | exact: False | approximate: True  | maxdiff: 2.3283064365386963e-10\n",
            "key11           | exact: False | approximate: True  | maxdiff: 2.546585164964199e-11\n",
            "query11         | exact: False | approximate: True  | maxdiff: 1.8189894035458565e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jvEzOKJjTDe",
        "outputId": "ab67ca58-da11-45d9-aaa7-11b1b43e2ce3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-28 23:50:06--  https://raw.githubusercontent.com/piyush-jena/pos_tagging_transformer/main/data/test_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 737353 (720K) [text/plain]\n",
            "Saving to: ‘test_data.csv’\n",
            "\n",
            "test_data.csv       100%[===================>] 720.07K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-12-28 23:50:07 (14.6 MB/s) - ‘test_data.csv’ saved [737353/737353]\n",
            "\n",
            "--2023-12-28 23:50:07--  https://raw.githubusercontent.com/piyush-jena/pos_tagging_transformer/main/data/train_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3235899 (3.1M) [text/plain]\n",
            "Saving to: ‘train_data.csv’\n",
            "\n",
            "train_data.csv      100%[===================>]   3.09M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-12-28 23:50:07 (46.2 MB/s) - ‘train_data.csv’ saved [3235899/3235899]\n",
            "\n",
            "--2023-12-28 23:50:07--  https://raw.githubusercontent.com/piyush-jena/pos_tagging_transformer/main/data/valid_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 813521 (794K) [text/plain]\n",
            "Saving to: ‘valid_data.csv’\n",
            "\n",
            "valid_data.csv      100%[===================>] 794.45K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-12-28 23:50:08 (17.8 MB/s) - ‘valid_data.csv’ saved [813521/813521]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WgzO1Y971dNJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}